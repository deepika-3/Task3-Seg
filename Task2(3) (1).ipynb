{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBlFIQunCUmh",
        "outputId": "585e1f9f-7df5-4bdb-a45a-e4a3ea82a7c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conv3d(3, 64, kernel_size=(3, 7, 7), stride=(1, 2, 2), padding=(1, 3, 3), bias=False)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "def inflate_conv2d_to_conv3d(conv2d_layer, depth=3):\n",
        "    assert isinstance(conv2d_layer, nn.Conv2d)\n",
        "    out_c, in_c, h, w = conv2d_layer.weight.shape\n",
        "    conv3d_layer = nn.Conv3d(\n",
        "        in_c, out_c, (depth, h, w),\n",
        "        stride=(1, *conv2d_layer.stride),\n",
        "        padding=(depth // 2, *conv2d_layer.padding),\n",
        "        bias=conv2d_layer.bias is not None\n",
        "    )\n",
        "    weight2d = conv2d_layer.weight.data.unsqueeze(2)\n",
        "    weight3d = weight2d.repeat(1, 1, depth, 1, 1)\n",
        "    weight3d = weight3d / depth\n",
        "    conv3d_layer.weight.data.copy_(weight3d)\n",
        "    if conv2d_layer.bias is not None:\n",
        "        conv3d_layer.bias.data.copy_(conv2d_layer.bias.data)\n",
        "    return conv3d_layer\n",
        "    print(conv3d_layer)\n",
        "\n",
        "def inflate_densenet2d_to_3d(model_2d, depth=3):\n",
        "    for name, module in model_2d.named_children():\n",
        "        if isinstance(module, nn.Conv2d):\n",
        "            setattr(model_2d, name, inflate_conv2d_to_conv3d(module, depth=depth))\n",
        "        else:\n",
        "            inflate_densenet2d_to_3d(module, depth=depth)\n",
        "    return model_2d\n",
        "    print(model_2d)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    model_2d = models.densenet121(pretrained=True)\n",
        "    model_3d = inflate_densenet2d_to_3d(model_2d, depth=3)\n",
        "    print(model_3d.features.conv0)  # Example output"
      ]
    }
  ]
}